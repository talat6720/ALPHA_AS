{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binaryNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading psycopg2_binary-2.9.9-cp311-cp311-win_amd64.whl.metadata (4.6 kB)\n",
      "Downloading psycopg2_binary-2.9.9-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.2 MB 991.0 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.1/1.2 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.3/1.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.5/1.2 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.6/1.2 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.8/1.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.0/1.2 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 3.2 MB/s eta 0:00:00\n",
      "Installing collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.9\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TalatZakirhusenSayye\\AppData\\Local\\Temp\\ipykernel_7268\\1041193305.py:13: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, Column, Integer, Float, String, DateTime\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import re\n",
    "from sklearn.impute import KNNImputer\n",
    "from sqlalchemy import text\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define the database model using SQLAlchemy's Declarative System\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define a class for the OptimusData table\n",
    "class OptimusData(Base):\n",
    "    __tablename__ = 'optimus_data'\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    # Define columns based on the structure of your Excel file or data source\n",
    "    TRANSPORTATION_COST = Column(Float)\n",
    "    QTY = Column(Integer)\n",
    "    SKU_REVENUE = Column(Float)\n",
    "    Total_Pallets = Column(Integer)\n",
    "    Total_Packages = Column(Integer)\n",
    "    Total_MPF = Column(Float)\n",
    "    # Add additional fields as necessary based on your data structure\n",
    "\n",
    "# Define additional models for storing KPIs (Key Performance Indicators)\n",
    "class MonthlyKPIs(Base):\n",
    "    __tablename__ = 'monthly_kpis'\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    Year = Column(Integer)\n",
    "    Month = Column(String)\n",
    "    Total_Units = Column(Integer)\n",
    "    Total_Pallets = Column(Integer)\n",
    "    Total_Packages = Column(Integer)\n",
    "    Total_MPF = Column(Float)\n",
    "\n",
    "class TotalMPFPerTransportType(Base):\n",
    "    __tablename__ = 'total_mpf_per_transport_type'\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    TRANSPORT_TYPE = Column(String)\n",
    "    Total_MPF = Column(Float)\n",
    "\n",
    "class TotalRevenuePerCategory(Base):\n",
    "    __tablename__ = 'total_revenue_per_category'\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    CATEGORY = Column(String)\n",
    "    SKU_REVENUE = Column(Float)\n",
    "\n",
    "class TotalTransportCostPerConsignee(Base):\n",
    "    __tablename__ = 'total_transport_cost_per_consignee'\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    CONSIGNEE = Column(String)\n",
    "    TRANSPORTATION_COST = Column(Float)\n",
    "\n",
    "# Define a class for the DateDimension table to store date-related information\n",
    "class DateDimension(Base):\n",
    "    __tablename__ = 'date_dimension'\n",
    "    date = Column(DateTime, primary_key=True)\n",
    "    year = Column(Integer)\n",
    "    month = Column(Integer)\n",
    "    day = Column(Integer)\n",
    "    week = Column(Integer)\n",
    "    quarter = Column(Integer)\n",
    "    day_of_week = Column(Integer)\n",
    "    month_name = Column(String)\n",
    "    day_name = Column(String)\n",
    "\n",
    "# Initialize the database connection and create tables if they don't exist\n",
    "engine = create_engine('sqlite:///optimus_data.db')\n",
    "Base.metadata.create_all(engine)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Function to populate the DateDimension table with dates between start_date and end_date\n",
    "def populate_date_dimension(start_date, end_date):\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        date_dim = DateDimension(\n",
    "            date=current_date,\n",
    "            year=current_date.year,\n",
    "            month=current_date.month,\n",
    "            day=current_date.day,\n",
    "            week=current_date.isocalendar()[1],\n",
    "            quarter=(current_date.month - 1) // 3 + 1,\n",
    "            day_of_week=current_date.weekday(),\n",
    "            month_name=current_date.strftime('%B'),\n",
    "            day_name=current_date.strftime('%A'),\n",
    "        )\n",
    "        session.add(date_dim)\n",
    "        current_date += timedelta(days=1)\n",
    "    session.commit()\n",
    "\n",
    "# Example usage of the function to populate the DateDimension table\n",
    "populate_date_dimension(datetime(2010, 1, 1), datetime(2030, 12, 31))\n",
    "\n",
    "# Function to generate a data quality report for a given DataFrame\n",
    "def generate_data_quality_report(df, output_file_path):\n",
    "    # Calculate the total number of rows in the DataFrame\n",
    "    total_rows = {'Total Rows': [len(df)]}\n",
    "    df_total_rows = pd.DataFrame(total_rows)\n",
    "    \n",
    "    # Calculate missing values count before any data imputation\n",
    "    missing_values_before = df.isnull().sum()\n",
    "    \n",
    "    # Generate a basic data summary for each column in the DataFrame\n",
    "    data_summary = df.describe(include='all')\n",
    "    \n",
    "    # Save the generated reports to an Excel file at the specified path\n",
    "    with pd.ExcelWriter(output_file_path) as writer:\n",
    "        df_total_rows.to_excel(writer, sheet_name='Total Rows', index=False)\n",
    "        missing_values_before.to_frame(name='Missing Values Before').to_excel(writer, sheet_name='Missing Values Before')\n",
    "        data_summary.to_excel(writer, sheet_name='Data Summary')\n",
    "        \n",
    "    print(f\"Data quality report saved to {output_file_path}\")\n",
    "\n",
    "# Function to process Optimus data, generate KPIs, and insert data into the database\n",
    "def process_optimus_data(file_path, quality_report_path):\n",
    "    # Nested function to parse packing details from a row of data\n",
    "    def parse_packing_details(row):\n",
    "        pallets, packages = 0, 0\n",
    "        # Iterate through specific columns containing packing details and parse them\n",
    "        for col in ['PACKING_DETAILS_01', 'PACKING_DETAILS_02', 'PACKING_DETAILS_03', 'PACKING_DETAILS_04']:\n",
    "            if pd.notna(row[col]):\n",
    "                details = row[col].split(';')\n",
    "                if 'PALLET' in details:\n",
    "                    pallets += int(details[0])\n",
    "                elif 'PACKAGE' in details:\n",
    "                    packages += int(details[0])\n",
    "        return pallets, packages\n",
    "\n",
    "    # Function to calculate the MPF based on transportation cost\n",
    "    def calculate_mpf(transportation_cost):\n",
    "        if transportation_cost < 2500:\n",
    "            return 2.18\n",
    "        mpf = transportation_cost * 0.003464\n",
    "        return max(26.22, min(mpf, 508.70))\n",
    "\n",
    "    # Read data from the specified Excel file\n",
    "    df = pd.read_excel(file_path, sheet_name='DATA')\n",
    "    \n",
    "    # Generate a Data Quality Report before performing any imputation\n",
    "    generate_data_quality_report(df, quality_report_path)\n",
    "    \n",
    "    # Debugging: Print the shape of the DataFrame before imputation\n",
    "    print(\"Shape of the DataFrame before imputation:\", df.shape)\n",
    "    \n",
    "    # Identify numerical columns for imputation\n",
    "    numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    imputer = KNNImputer()\n",
    "    imputed_data = imputer.fit_transform(df[numerical_cols])\n",
    "\n",
    "    # Debugging: Print information about imputed data\n",
    "    print(\"Numerical columns selected for imputation:\", numerical_cols)\n",
    "    print(\"Shape of imputed data:\", imputed_data.shape)\n",
    "    \n",
    "    # Update the original DataFrame with the imputed numerical data\n",
    "    df[numerical_cols] = pd.DataFrame(imputed_data, columns=numerical_cols, index=df.index)\n",
    "\n",
    "    # Fill missing values in non-numerical columns with 'Unknown'\n",
    "    non_numerical_cols = df.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "    for col in non_numerical_cols:\n",
    "        df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "    # Apply parsing function to each row to extract packing details\n",
    "    df[['Total_Pallets', 'Total_Packages']] = df.apply(parse_packing_details, axis=1, result_type='expand')\n",
    "    # Apply function to calculate MPF based on transportation cost\n",
    "    df['Total_MPF'] = df['TRANSPORTATION_COST'].apply(calculate_mpf)\n",
    "\n",
    "    # Convert pickup dates to datetime format and extract month and year\n",
    "    df['PICKUP_DATE'] = pd.to_datetime(df['PICKUP_DATE'].apply(lambda x: x.split(' ')[0]), errors='coerce')\n",
    "    df['Month'] = df['PICKUP_DATE'].dt.month\n",
    "    df['Year'] = df['PICKUP_DATE'].dt.year\n",
    "\n",
    "    # Aggregate data to calculate monthly totals for various KPIs\n",
    "    monthly_totals = df.groupby(['Year', 'Month']).agg(\n",
    "        Total_Units=('QTY', 'sum'),\n",
    "        Total_Pallets=('Total_Pallets', 'sum'),\n",
    "        Total_Packages=('Total_Packages', 'sum'),\n",
    "        Total_MPF=('Total_MPF', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Calculate baseline values for comparison\n",
    "    baseline = monthly_totals[monthly_totals['Month'].isin([1, 2])].groupby('Year').mean().reset_index()\n",
    "    baseline['Month'] = 'Baseline'\n",
    "    monthly_kpis = pd.concat([baseline, monthly_totals])\n",
    "\n",
    "    # Aggregate data for other KPIs based on different groupings\n",
    "    total_mpf_per_transport_type = df.groupby('TRANSPORT_TYPE')['Total_MPF'].sum().reset_index()\n",
    "    total_revenue_per_category = df.groupby('CATEGORY')['SKU_REVENUE'].sum().reset_index()\n",
    "    total_transport_cost_per_consignee = df.groupby('CONSIGNEE')['TRANSPORTATION_COST'].sum().reset_index()\n",
    "\n",
    "    # Insert KPIs into the database\n",
    "    insert_kpis_into_db(session, monthly_kpis, MonthlyKPIs, [\n",
    "        'Year', 'Month', 'Total_Units', 'Total_Pallets', 'Total_Packages', 'Total_MPF'\n",
    "    ])\n",
    "    insert_kpis_into_db(session, total_mpf_per_transport_type, TotalMPFPerTransportType, ['TRANSPORT_TYPE', 'Total_MPF'])\n",
    "    insert_kpis_into_db(session, total_revenue_per_category, TotalRevenuePerCategory, ['CATEGORY', 'SKU_REVENUE'])\n",
    "    insert_kpis_into_db(session, total_transport_cost_per_consignee, TotalTransportCostPerConsignee, ['CONSIGNEE', 'TRANSPORTATION_COST'])\n",
    "\n",
    "# Function to insert KPIs into the database\n",
    "def insert_kpis_into_db(session, df, ModelClass, columns):\n",
    "    for _, row in df.iterrows():\n",
    "        # Create a record for each row in the DataFrame and add it to the session\n",
    "        record = ModelClass(**{col: row[col] for col in columns})\n",
    "        session.add(record)\n",
    "    session.commit()\n",
    "    \n",
    "    # Try-catch block for error handling during database insertion\n",
    "    try:\n",
    "        for _, row in df.iterrows():\n",
    "            # Insert data into the OptimusData table\n",
    "            data_record = OptimusData(\n",
    "                TRANSPORTATION_COST=row.get('TRANSPORTATION_COST', None),\n",
    "                QTY=row.get('QTY', None),\n",
    "                SKU_REVENUE=row.get('SKU_REVENUE', None),\n",
    "                # Map other fields as necessary based on your data structure\n",
    "            )\n",
    "            session.add(data_record)\n",
    "        session.commit()\n",
    "        print(\"Data successfully inserted into the database.\")\n",
    "    except Exception as e:\n",
    "        # Roll back the session in case of an error\n",
    "        session.rollback()\n",
    "        print(f\"Error inserting data into database: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\TalatZakirhusenSayye\\Desktop\\alpha\n",
      "Database path: sqlite:///optimus_data.db\n",
      "Data quality report saved to C:\\Users\\TalatZakirhusenSayye\\Downloads\\data_quality_report.xlsx\n",
      "Shape of the DataFrame before imputation: (112900, 21)\n",
      "Numerical columns selected for imputation: Index(['Unnamed: 0', 'QTY', 'SKU_REVENUE', 'TRANSPORTATION_COST'], dtype='object')\n",
      "Shape of imputed data: (112900, 4)\n",
      "Data successfully inserted into the database.\n",
      "Data successfully inserted into the database.\n",
      "Data successfully inserted into the database.\n",
      "Data successfully inserted into the database.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Current working directory:\", os.getcwd())\n",
    "    database_path = 'sqlite:///optimus_data.db'\n",
    "    print(f\"Database path: {database_path}\")\n",
    "    \n",
    "    engine = create_engine(database_path)\n",
    "    Base.metadata.create_all(engine)  \n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "     # Update this path\n",
    "    file_path = 'C:\\\\Users\\\\TalatZakirhusenSayye\\\\Downloads\\\\ALPHA.xlsx' \n",
    "    quality_report_path = 'C:\\\\Users\\\\TalatZakirhusenSayye\\\\Downloads\\\\data_quality_report.xlsx'\n",
    "    process_optimus_data(file_path, quality_report_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
